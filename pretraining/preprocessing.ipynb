{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from grelu.data.preprocess import filter_blacklist, filter_chromosomes\n",
    "from grelu.variant import filter_variants\n",
    "import os\n",
    "from typing import Callable, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from einops import rearrange\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from grelu.data.augment import Augmenter, _split_overall_idx\n",
    "from grelu.data.utils import _check_multiclass, _create_task_data\n",
    "from grelu.sequence.format import (\n",
    "    INDEX_TO_BASE_HASH,\n",
    "    check_intervals,\n",
    "    convert_input_type,\n",
    "    get_input_type,\n",
    "    indices_to_one_hot,\n",
    "    strings_to_indices,\n",
    ")\n",
    "from grelu.sequence.mutate import mutate\n",
    "from grelu.sequence.utils import dinuc_shuffle, get_lengths, resize\n",
    "from grelu.utils import get_aggfunc, get_transform_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EUR.csv\") # this file can be downloaded from UKBioBank website.\n",
    "\n",
    "df['chrom'] =['chr' + str(i) for i in df['chrom']]\n",
    "variants = df\n",
    "variants = filter_chromosomes(variants, include='autosomesXY')\n",
    "variants = filter_blacklist(variants, genome=\"hg19\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class VariantLenDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class to perform inference on sequence variants.\n",
    "\n",
    "    Args:\n",
    "        variants: pd.DataFrame with columns \"chrom\", \"pos\", \"ref\", \"alt\".\n",
    "        seq_len: Uniform expected length (in base pairs) for output sequences\n",
    "        genome: The name of the genome from which to read sequences.\n",
    "        rc: If True, sequences will be augmented by reverse complementation. If\n",
    "            False, they will not be reverse complemented.\n",
    "        max_seq_shift: Maximum number of bases to shift the sequence for augmentation.\n",
    "            This is normally a small value (< 10). If 0, sequences will not\n",
    "            be augmented by shifting.\n",
    "        frac_mutation: Fraction of bases to randomly mutate for data augmentation.\n",
    "        protect: A list of positions to protect from mutation.\n",
    "        n_mutated_seqs: Number of mutated sequences to generate from each input\n",
    "            sequence for data augmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        variants: pd.DataFrame,\n",
    "        seq_len: int,\n",
    "        genome: Optional[str] = None,\n",
    "        rc: bool = False,\n",
    "        max_seq_shift: int = 0,\n",
    "        frac_mutation: float = 0.0,\n",
    "        n_mutated_seqs: int = 1,\n",
    "        protect: Optional[List[int]] = None,\n",
    "        seed: Optional[int] = None,\n",
    "        augment_mode: str = \"serial\",\n",
    "    ) -> None:\n",
    "        # Save params\n",
    "        self.genome = genome\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Save augmentation params\n",
    "        self.rc = rc\n",
    "        self.max_seq_shift = max_seq_shift\n",
    "        self.frac_mutated_bases = frac_mutation\n",
    "        self.n_mutated_bases = int(self.frac_mutated_bases * self.seq_len)\n",
    "        self.n_mutated_seqs = n_mutated_seqs\n",
    "\n",
    "        # Ingest alleles\n",
    "        self._load_alleles(variants)\n",
    "        self.n_alleles = 2\n",
    "\n",
    "        # Ingest sequences\n",
    "        self._load_seqs(variants)\n",
    "        self.n_seqs = self.seqs.shape[0]\n",
    "\n",
    "        # Protect central positions for mutation\n",
    "        if protect is None:\n",
    "            self.protect = [seq_len // 2]\n",
    "        else:\n",
    "            self.protect = protect\n",
    "\n",
    "        # Create augmenter\n",
    "        self.augmenter = Augmenter(\n",
    "            rc=self.rc,\n",
    "            max_seq_shift=self.max_seq_shift,\n",
    "            n_mutated_seqs=self.n_mutated_seqs,\n",
    "            n_mutated_bases=self.n_mutated_bases,\n",
    "            protect=self.protect,\n",
    "            seq_len=self.seq_len,\n",
    "            seed=seed,\n",
    "            mode=augment_mode,\n",
    "        )\n",
    "        self.n_augmented = len(self.augmenter)\n",
    "\n",
    "    def _load_alleles(self, variants: pd.DataFrame) -> None:\n",
    "        try:\n",
    "            self.ref = strings_to_indices(variants.ref.tolist())\n",
    "            self.alt = strings_to_indices(list(variants.alt.values))\n",
    "        except:\n",
    "            self.ref = strings_to_indices([variants.ref])\n",
    "            self.alt = strings_to_indices([variants.alt])\n",
    "\n",
    "    def _load_seqs(self, variants: pd.DataFrame) -> None:\n",
    "        from grelu.variant import variants_to_intervals\n",
    "\n",
    "        self.padded_seq_len = self.seq_len + (2 * self.max_seq_shift)\n",
    "        self.intervals = variants_to_intervals(variants, seq_len=self.padded_seq_len)\n",
    "        self.seqs = convert_input_type(self.intervals, \"indices\", genome=self.genome)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.n_seqs * self.n_augmented * 2\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tensor:\n",
    "        # Get indices\n",
    "        seq_idx, augment_idx, allele_idx = _split_overall_idx(\n",
    "            idx, (self.n_seqs, self.n_augmented, self.n_alleles)\n",
    "        )\n",
    "\n",
    "        # Extract current sequence and alleles\n",
    "        seq = self.seqs[seq_idx]\n",
    "\n",
    "        # Insert the allele\n",
    "        if allele_idx:\n",
    "            alt = self.alt[seq_idx]\n",
    "            seq = mutate(seq, alt, input_type=\"indices\")\n",
    "        else:\n",
    "            ref = self.ref[seq_idx]\n",
    "            seq = mutate(seq, ref, input_type=\"indices\")\n",
    "\n",
    "        # Augment current sequence\n",
    "        seq = self.augmenter(seq=seq, idx=augment_idx)\n",
    "\n",
    "        # One-hot encode\n",
    "        return indices_to_one_hot(seq)\n",
    "\n",
    "seq_all = []\n",
    "for i in variants.index:\n",
    "    df_new = pd.DataFrame()\n",
    "    for item in variants.columns:\n",
    "        df_new[item] = [variants.loc[i][item]]\n",
    "    print(df_new)\n",
    "    vr = grelu.variant.variant_to_seqs(df_new['chrom'].values[0],df_new['pos'].values[0], df_new['ref'].values[0], df_new['alt'].values[0], 'hg19', 512)\n",
    "    seq_all.append(vr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('variant_list_part1.pickle', 'wb') as handle:\n",
    "    pickle.dump(seq_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = seq_all\n",
    "\n",
    "df_train = df.iloc[0:int(len(df)*0.8)]\n",
    "df_test = df.iloc[int(len(df)*0.8):]\n",
    "\n",
    "\n",
    "\n",
    "df_train.to_csv(\"./ukbb_allinfo_13000000_train.csv\", index=None)\n",
    "df_test.to_csv(\"./ukbb_allinfo_13000000_test.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
